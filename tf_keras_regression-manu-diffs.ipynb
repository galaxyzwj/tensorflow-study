{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.18.0\n",
      "sklearn 0.21.3\n",
      "pandas 0.25.3\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl #画图用的库\n",
    "import matplotlib.pyplot as plt\n",
    "#下面这一句是为了可以在notebook中画图\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn   #机器学习算法库\n",
    "import pandas as pd #处理数据的库   \n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras   #使用tensorflow中的keras\n",
    "#import keras #单纯的使用keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, sklearn, pd, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "#引用位于sklearn数据集中的房价预测数据集\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR) #数据集的描述\n",
    "print(housing.data.shape) #相当于 x\n",
    "print(housing.target.shape) #相当于 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 8) (15480,)\n",
      "(5160, 8) (5160,)\n",
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n"
     ]
    }
   ],
   "source": [
    "#用sklearn中专门用于划分训练集和测试集的方法\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_test_split默认将数据划分为3:1，我们可以通过修改test_size值来改变数据划分比例(默认0.25，即3:1)\n",
    "#将总数乘以test_size就表示test测试集、valid验证集数量\n",
    "#将数据集整体拆分为train_all和test数据集\n",
    "x_train_all,x_test, y_train_all,y_test = train_test_split(housing.data, housing.target, random_state=7)\n",
    "#将train_all数据集拆分为train训练集和valid验证集\n",
    "x_train,x_valid, y_train,y_valid = train_test_split(x_train_all, y_train_all, random_state=11)\n",
    "\n",
    "print(x_train_all.shape,y_train_all.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练数据归一化处理\n",
    "# x = (x - u)/std  u为均值，std为方差\n",
    "from sklearn.preprocessing import StandardScaler #使用sklearn中的StandardScaler实现训练数据归一化\n",
    "\n",
    "scaler = StandardScaler()#初始化一个scaler对象\n",
    "x_train_scaler = scaler.fit_transform(x_train)#x_train已经是二维数据了，无需astype转换\n",
    "x_valid_scaler = scaler.transform(x_valid)\n",
    "x_test_scaler  = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#metric使用\n",
    "\n",
    "#直接调用均方差函数 MeanSquaredError()\n",
    "metric=keras.metrics.MeanSquaredError()\n",
    "print(metric([5.], [2.]))#这里单独输出为 9\n",
    "print(metric([0.], [1.]))#这里单独输出为 1\n",
    "print(metric.result())#累加总的结果输出为 1/2 * (9+1) = 5\n",
    "\n",
    "#不想累加的话调用reset_states\n",
    "metric.reset_states()\n",
    "metric([1.],[3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0  train mse: 2.0847263\t valid mse:  1.4750860630306017\n",
      "Epoch 1  train mse: 1.3247944\t valid mse:  1.4169727090294006\n",
      "Epoch 2  train mse: 1.3173337\t valid mse:  1.4008404432441943\n",
      "Epoch 3  train mse: 1.2927386\t valid mse:  1.393331363303617\n",
      "Epoch 4  train mse: 1.2736323\t valid mse:  1.3957328946278167\n",
      "Epoch 5  train mse: 1.2823045\t valid mse:  1.3924527819563814\n",
      "Epoch 6  train mse: 1.2335141\t valid mse:  1.3989454292405405\n",
      "Epoch 7  train mse: 1.2695118\t valid mse:  1.387919197915353\n",
      "Epoch 8  train mse: 1.2374288\t valid mse:  1.389155003960776\n",
      "Epoch 9  train mse: 1.2795521\t valid mse:  1.3895107881259308\n",
      "Epoch 10  train mse: 1.2795583\t valid mse:  1.3876356414847781\n",
      "Epoch 11  train mse: 1.2355306\t valid mse:  1.394336703074077\n",
      "Epoch 12  train mse: 1.2578385\t valid mse:  1.3852736655092535\n",
      "Epoch 13  train mse: 1.2670468\t valid mse:  1.3846958866071064\n",
      "Epoch 14  train mse: 1.2301608\t valid mse:  1.385985500328068\n",
      "Epoch 15  train mse: 1.2445643\t valid mse:  1.3849857609850613\n",
      "Epoch 16  train mse: 1.2513558\t valid mse:  1.3869940994700296\n",
      "Epoch 17  train mse: 1.2750232\t valid mse:  1.3893256947169441\n",
      "Epoch 18  train mse: 1.2893525\t valid mse:  1.3860260648062497\n",
      "Epoch 19  train mse: 1.2430159\t valid mse:  1.3852249534654613\n",
      "Epoch 20  train mse: 1.2846347\t valid mse:  1.385104240950519\n",
      "Epoch 21  train mse: 1.2404712\t valid mse:  1.3849452506641957\n",
      "Epoch 22  train mse: 1.2651192\t valid mse:  1.3842767530750484\n",
      "Epoch 23  train mse: 1.2670141\t valid mse:  1.3867431891688213\n",
      "Epoch 24  train mse: 1.2444266\t valid mse:  1.3864198447301956\n",
      "Epoch 25  train mse: 1.2508397\t valid mse:  1.3906368986486524\n",
      "Epoch 26  train mse: 1.2669005\t valid mse:  1.3874063596557609\n",
      "Epoch 27  train mse: 1.235916\t valid mse:  1.402920795353835\n",
      "Epoch 28  train mse: 1.2461712\t valid mse:  1.3905526215549877\n",
      "Epoch 29  train mse: 1.2258122\t valid mse:  1.3949245786956903\n",
      "Epoch 30  train mse: 1.2617296\t valid mse:  1.3857951122845469\n",
      "Epoch 31  train mse: 1.2621322\t valid mse:  1.3851742625321644\n",
      "Epoch 32  train mse: 1.2429788\t valid mse:  1.3836917316448323\n",
      "Epoch 33  train mse: 1.2356339\t valid mse:  1.3877324348707571\n",
      "Epoch 34  train mse: 1.2821807\t valid mse:  1.3842064342783515\n",
      "Epoch 35  train mse: 1.27052\t valid mse:  1.3835722890327629\n",
      "Epoch 36  train mse: 1.2615987\t valid mse:  1.394258771881915\n",
      "Epoch 37  train mse: 1.2467527\t valid mse:  1.3849141942656449\n",
      "Epoch 38  train mse: 1.2773468\t valid mse:  1.383699064274973\n",
      "Epoch 39  train mse: 1.2586939\t valid mse:  1.3872942136204012\n",
      "Epoch 40  train mse: 1.2531147\t valid mse:  1.3885664065963945\n",
      "Epoch 41  train mse: 1.2309846\t valid mse:  1.3858065934917612\n",
      "Epoch 42  train mse: 1.2234867\t valid mse:  1.391426715475855\n",
      "Epoch 43  train mse: 1.2440645\t valid mse:  1.383648327751918\n",
      "Epoch 44  train mse: 1.2571067\t valid mse:  1.3841037007623913\n",
      "Epoch 45  train mse: 1.273862\t valid mse:  1.3862783968823624\n",
      "Epoch 46  train mse: 1.2480733\t valid mse:  1.3837334640660142\n",
      "Epoch 47  train mse: 1.2583495\t valid mse:  1.3878258448339666\n",
      "Epoch 48  train mse: 1.241835\t valid mse:  1.3841765139658904\n",
      "Epoch 49  train mse: 1.2690344\t valid mse:  1.3832597951435641\n",
      "Epoch 50  train mse: 1.2766293\t valid mse:  1.3854065552713632\n",
      "Epoch 51  train mse: 1.2599555\t valid mse:  1.388113770725053\n",
      "Epoch 52  train mse: 1.2566489\t valid mse:  1.3836650994237747\n",
      "Epoch 53  train mse: 1.2394506\t valid mse:  1.3859333561397027\n",
      "Epoch 54  train mse: 1.285308\t valid mse:  1.3906771934662157\n",
      "Epoch 55  train mse: 1.2893232\t valid mse:  1.3901439656976295\n",
      "Epoch 56  train mse: 1.2686529\t valid mse:  1.386671863167415\n",
      "Epoch 57  train mse: 1.2506766\t valid mse:  1.3868752261980901\n",
      "Epoch 58  train mse: 1.283295\t valid mse:  1.3861692382388808\n",
      "Epoch 59  train mse: 1.2677544\t valid mse:  1.391379721919622\n",
      "Epoch 60  train mse: 1.2452192\t valid mse:  1.3883756036997632\n",
      "Epoch 61  train mse: 1.2512343\t valid mse:  1.385123175264689\n",
      "Epoch 62  train mse: 1.2442666\t valid mse:  1.3838084250085332\n",
      "Epoch 63  train mse: 1.2587008\t valid mse:  1.3846451786512186\n",
      "Epoch 64  train mse: 1.242743\t valid mse:  1.3840085727441631\n",
      "Epoch 65  train mse: 1.2605458\t valid mse:  1.3854969340328396\n",
      "Epoch 66  train mse: 1.2746941\t valid mse:  1.386122659084794\n",
      "Epoch 67  train mse: 1.2450782\t valid mse:  1.3867741082419214\n",
      "Epoch 68  train mse: 1.2379215\t valid mse:  1.388587374541316\n",
      "Epoch 69  train mse: 1.2514465\t valid mse:  1.3889286247628128\n",
      "Epoch 70  train mse: 1.250907\t valid mse:  1.391401284538879\n",
      "Epoch 71  train mse: 1.2750472\t valid mse:  1.3832588636601555\n",
      "Epoch 72  train mse: 1.2827257\t valid mse:  1.3895191565157865\n",
      "Epoch 73  train mse: 1.2796383\t valid mse:  1.3828297519693824\n",
      "Epoch 74  train mse: 1.22639994\t valid mse:  1.38510389977568\n",
      "Epoch 75  train mse: 1.2431728\t valid mse:  1.3899108155910356\n",
      "Epoch 76  train mse: 1.2933995\t valid mse:  1.3832907473886975\n",
      "Epoch 77  train mse: 1.2633421\t valid mse:  1.3837716329570855\n",
      "Epoch 78  train mse: 1.2463418\t valid mse:  1.3853580250363837\n",
      "Epoch 79  train mse: 1.2444445\t valid mse:  1.3835966610514887\n",
      "Epoch 80  train mse: 1.2528017\t valid mse:  1.386097707882695\n",
      "Epoch 81  train mse: 1.2315915\t valid mse:  1.3973325292862437\n",
      "Epoch 82  train mse: 1.2603254\t valid mse:  1.3830809389354004\n",
      "Epoch 83  train mse: 1.2643194\t valid mse:  1.386310184108398\n",
      "Epoch 84  train mse: 1.2619162\t valid mse:  1.3886742737748126\n",
      "Epoch 85  train mse: 1.2882746\t valid mse:  1.3830094376987887\n",
      "Epoch 86  train mse: 1.2491027\t valid mse:  1.3848419789690771\n",
      "Epoch 87  train mse: 1.2403897\t valid mse:  1.3855859659370808\n",
      "Epoch 88  train mse: 1.2612848\t valid mse:  1.3843251380295571\n",
      "Epoch 89  train mse: 1.271977\t valid mse:  1.3895024263587519\n",
      "Epoch 90  train mse: 1.2745076\t valid mse:  1.3834182984570549\n",
      "Epoch 91  train mse: 1.2465816\t valid mse:  1.3834527635170473\n",
      "Epoch 92  train mse: 1.244389\t valid mse:  1.3837143919403194\n",
      "Epoch 93  train mse: 1.2407447\t valid mse:  1.3830578510518465\n",
      "Epoch 94  train mse: 1.2641735\t valid mse:  1.391055645507521\n",
      "Epoch 95  train mse: 1.250431\t valid mse:  1.3905354933891365\n",
      "Epoch 96  train mse: 1.2681997\t valid mse:  1.3997584189926924\n",
      "Epoch 97  train mse: 1.2366349\t valid mse:  1.3857367820002182\n",
      "Epoch 98  train mse: 1.2517695\t valid mse:  1.386019942006524\n",
      "Epoch 99  train mse: 1.2483735\t valid mse:  1.3871708945941383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#tf.keras.models.Sequential()建立模型\\n\\nmodel = keras.models.Sequential([\\n    keras.layers.Dense(30, activation=\"relu\",input_shape=x_train.shape[1:]),\\n    keras.layers.Dense(1),\\n])\\n#编译model。 loss目标函数为均方差，这里表面上是字符串，实际上tensorflow中会映射到对应的算法函数，我们也可以自定义\\nmodel.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\\n\\n#使用监听模型训练过程中的callbacks\\nlogdir=\\'./callbacks_regression\\'\\nif not os.path.exists(logdir):\\n    os.mkdir(logdir)\\noutput_model_file = os.path.join(logdir,\"regression_california_housing.h5\")\\n\\n#首先定义一个callback数组\\ncallbacks = [\\n    keras.callbacks.TensorBoard(logdir),\\n    keras.callbacks.ModelCheckpoint(output_model_file,save_best_only=True),\\n    keras.callbacks.EarlyStopping(patience=5,min_delta=1e-3)\\n]\\n\\n#查看model的架构\\nmodel.summary()\\n\\nhistory=model.fit(x_train_scaler,y_train,epochs=100,\\n                 validation_data=(x_valid_scaler,y_valid),\\n                 callbacks=callbacks)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.batch 遍历训练集 metric\n",
    "#      自动求导\n",
    "#2. epoch结束 验证集 metric\n",
    "epochs=100\n",
    "batch_size=32#batch_size表示一次训练的样本数\n",
    "steps_per_epoch=len(x_train_scaler) // batch_size # 除以batch_size结果取整，表示每个epoch训练样本的次数\n",
    "optimizer=keras.optimizers.SGD()# optimizer选择 sgd\n",
    "metric=keras.metrics.MeanSquaredError()#损失函数 mse均方差\n",
    "\n",
    "#自定义一次随机训练取出的32个样本数\n",
    "def random_batch(x, y, batch_size=32):\n",
    "    idx=np.random.randint(0,len(x),size=batch_size)#从 0 到 len(x)总的数量中 随机取出32个索引\n",
    "    return x[idx],y[idx]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\",input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()#防止平方差值累加\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_batch, y_batch = random_batch(x_train_scaler, y_train, batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            loss = tf.reduce_mean(keras.losses.mean_squared_error(y_batch, y_pred))\n",
    "            metric(y_batch,y_pred)\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print(\"\\rEpoch\", epoch, \" train mse:\", metric.result().numpy(), end=\"\")\n",
    "    y_valid_pred = model(x_valid_scaler)\n",
    "    valid_loss = tf.reduce_mean(keras.losses.mean_squared_error(y_valid_pred, y_valid))\n",
    "    print(\"\\t\", \"valid mse: \", valid_loss.numpy())\n",
    "\n",
    "'''\n",
    "#tf.keras.models.Sequential()建立模型\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\",input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "#编译model。 loss目标函数为均方差，这里表面上是字符串，实际上tensorflow中会映射到对应的算法函数，我们也可以自定义\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "#使用监听模型训练过程中的callbacks\n",
    "logdir='./callbacks_regression'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir,\"regression_california_housing.h5\")\n",
    "\n",
    "#首先定义一个callback数组\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file,save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=5,min_delta=1e-3)\n",
    "]\n",
    "\n",
    "#查看model的架构\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(x_train_scaler,y_train,epochs=100,\n",
    "                 validation_data=(x_valid_scaler,y_valid),\n",
    "                 callbacks=callbacks)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印模型训练过程中的相关曲线\n",
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaler,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
